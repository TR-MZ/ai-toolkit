{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® AI Toolkit Web UI on Colab\n",
    "\n",
    "Run the full ai-toolkit training & generation web UI on **Colab's GPU** with public internet access.\n",
    "\n",
    "**Time to start**: ~5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üü¢ STEP 0: Mount Google Drive (for VAE + Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted at /content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your paths from Google Drive\n",
    "\n",
    "# üî¥ EDIT THESE with your Google Drive paths\n",
    "VAE_PATH = \"/content/drive/My Drive/checkpoint-7100\"  # Path to transparent VAE\n",
    "DATASET_PATHS = [\n",
    "    \"/content/drive/My Drive/dataset1\",\n",
    "    \"/content/drive/My Drive/dataset2\",\n",
    "    \"/content/drive/My Drive/dataset3\",\n",
    "]\n",
    "\n",
    "# Verify they exist\n",
    "print(\"üîç Checking paths...\\n\")\n",
    "\n",
    "if os.path.exists(VAE_PATH):\n",
    "    print(f\"‚úÖ VAE found at:\")\n",
    "    print(f\"   {VAE_PATH}\")\n",
    "else:\n",
    "    print(f\"‚ùå VAE not found at:\")\n",
    "    print(f\"   {VAE_PATH}\")\n",
    "    print(f\"   Make sure you uploaded checkpoint-7100 to Google Drive!\")\n",
    "\n",
    "print()\n",
    "for i, path in enumerate(DATASET_PATHS, 1):\n",
    "    if os.path.exists(path):\n",
    "        files = len(os.listdir(path))\n",
    "        print(f\"‚úÖ Dataset {i}: {files} files\")\n",
    "        print(f\"   {path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Dataset {i} not found\")\n",
    "        print(f\"   {path}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "source": "import os\nimport shutil\nfrom pathlib import Path\n\n# After cloning the repo, datasets will be here\ngit_datasets = Path(\"/content/ai-toolkit/datasets\")\ncolab_datasets = Path(\"/content/datasets\")\n\nprint(\"üìä Checking for datasets in git repo...\")\n\nif git_datasets.exists():\n    datasets = [d for d in git_datasets.iterdir() if d.is_dir()]\n    if datasets:\n        print(f\"\\n‚úÖ Found {len(datasets)} dataset(s) in git repo:\\n\")\n        \n        # Create /content/datasets if it doesn't exist\n        colab_datasets.mkdir(exist_ok=True)\n        \n        for dataset in datasets:\n            dest = colab_datasets / dataset.name\n            if not dest.exists():\n                print(f\"   üìÇ Copying {dataset.name}...\")\n                shutil.copytree(dataset, dest)\n            else:\n                print(f\"   ‚úÖ {dataset.name} already exists\")\n        \n        print(f\"\\n‚úÖ Datasets ready in: {colab_datasets}\")\n        print(f\"\\nUse in the web UI:\")\n        print(f\"   Datasets folder: /content/datasets\")\n    else:\n        print(\"No datasets found in git repo (that's OK!)\")\nelse:\n    print(f\"Datasets folder not found at {git_datasets}\")\n    print(\"(The git repo might not include datasets)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## (Optional) Copy Datasets from Git Repo\n\nIf you cloned datasets with the git repo, copy them here automatically:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"üñ•Ô∏è  GPU Info:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(\"   ‚úÖ GPU available!\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  WARNING: No GPU! Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone Repository\n",
    "\n",
    "‚ö†Ô∏è **Replace `YOUR_USERNAME`** with your GitHub username first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# üî¥ EDIT THIS LINE - Replace YOUR_USERNAME\n",
    "repo_url = \"https://github.com/YOUR_USERNAME/ai-toolkit-rgba.git\"\n",
    "\n",
    "repo_path = \"/content/ai-toolkit\"\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    print(f\"üì• Cloning {repo_url}...\")\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, repo_path], check=True)\n",
    "    print(\"‚úÖ Clone complete!\")\n",
    "else:\n",
    "    print(\"‚úÖ Already cloned\")\n",
    "\n",
    "os.chdir(repo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Install Dependencies\n",
    "\n",
    "‚è±Ô∏è This takes ~3-5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "\n",
    "# Node.js\n",
    "result = subprocess.run([\"node\", \"--version\"], capture_output=True)\n",
    "if result.returncode != 0:\n",
    "    print(\"   Installing Node.js...\")\n",
    "    subprocess.run([\"apt-get\", \"update\", \"-qq\"], capture_output=True)\n",
    "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"-qq\", \"nodejs\", \"npm\"], check=True)\n",
    "print(\"   ‚úÖ Node.js\")\n",
    "\n",
    "# npm packages\n",
    "print(\"   Installing npm packages...\")\n",
    "subprocess.run([\"npm\", \"install\", \"--prefix\", \"ui\"], capture_output=True, check=False)\n",
    "print(\"   ‚úÖ npm\")\n",
    "\n",
    "# localtunnel\n",
    "print(\"   Installing localtunnel...\")\n",
    "subprocess.run([\"npm\", \"install\", \"-g\", \"localtunnel\"], capture_output=True, check=False)\n",
    "print(\"   ‚úÖ localtunnel\")\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Build UI\n",
    "\n",
    "‚è±Ô∏è This takes ~2-3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"üî® Building Next.js UI...\")\n",
    "result = subprocess.run(\n",
    "    [\"npm\", \"run\", \"build\", \"--prefix\", \"ui\"],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ Build successful!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Build completed with warnings (usually OK)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Start Web UI\n",
    "\n",
    "üöÄ This creates a public URL you can access from anywhere!\n",
    "\n",
    "**Keep this cell running!** The public URL will appear below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.chdir(\"/content/ai-toolkit\")\n",
    "UI_PORT = 8675\n",
    "\n",
    "print(\"üöÄ Starting web UI server...\")\n",
    "ui_process = subprocess.Popen(\n",
    "    [\"npm\", \"run\", \"start\", \"--prefix\", \"ui\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Waiting 15 seconds for server to start...\")\n",
    "time.sleep(15)\n",
    "\n",
    "print(f\"\\nüåê Creating tunnel on port {UI_PORT}...\\n\")\n",
    "tunnel_process = subprocess.Popen(\n",
    "    [\"lt\", \"--port\", str(UI_PORT), \"--local-host\", \"127.0.0.1\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "# Read tunnel output\n",
    "url_found = False\n",
    "for line in tunnel_process.stdout:\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "        print(line)\n",
    "    \n",
    "    if \".loca.lt\" in line and not url_found:\n",
    "        url_found = True\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚úÖ WEB UI IS LIVE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nüîó PUBLIC URL:\\n\\n   {line}\\n\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nüìù What you can do:\")\n",
    "        print(\"   ‚Ä¢ Open the URL in your browser\")\n",
    "        print(\"   ‚Ä¢ Create training jobs (VAE + datasets auto-detected)\")\n",
    "        print(\"   ‚Ä¢ Generate images with LoRA\")\n",
    "        print(\"   ‚Ä¢ Monitor GPU/VRAM\")\n",
    "        print(\"\\n‚è±Ô∏è  Keep this cell running!\")\n",
    "        print(\"   You can open NEW cells to run other commands.\\n\")\n",
    "\n",
    "# Keep alive\n",
    "try:\n",
    "    tunnel_process.wait()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚èπÔ∏è  Shutting down...\")\n",
    "    tunnel_process.terminate()\n",
    "    ui_process.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Helper Commands\n",
    "\n",
    "Run these in separate cells while the server is running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU usage\n",
    "import subprocess\n",
    "result = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training outputs\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"/content/ai-toolkit/output\")\n",
    "if output_dir.exists():\n",
    "    print(\"üìÅ Training outputs:\")\n",
    "    for folder in sorted(output_dir.iterdir()):\n",
    "        if folder.is_dir():\n",
    "            print(f\"\\n   üìÇ {folder.name}\")\n",
    "            samples = list(folder.glob(\"*.png\"))\n",
    "            if samples:\n",
    "                print(f\"      Files: {len(samples)}\")\n",
    "else:\n",
    "    print(\"No outputs yet\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}