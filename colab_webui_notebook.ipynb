{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé® AI Toolkit Web UI on Colab\n",
        "\n",
        "Run the full ai-toolkit training & generation web UI on **Colab's GPU** with public internet access.\n",
        "\n",
        "**Time to start**: ~5 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üü¢ STEP 0: Mount Google Drive (for VAE + Datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted at /content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure your paths from Google Drive\n",
        "\n",
        "# üî¥ EDIT THESE with your Google Drive paths\n",
        "VAE_PATH = \"/content/drive/My Drive/checkpoint-7100\"  # Path to transparent VAE\n",
        "DATASET_PATHS = [\n",
        "    \"/content/drive/My Drive/dataset1\",\n",
        "    \"/content/drive/My Drive/dataset2\",\n",
        "    \"/content/drive/My Drive/dataset3\",\n",
        "]\n",
        "\n",
        "# Verify they exist\n",
        "print(\"üîç Checking paths...\\n\")\n",
        "\n",
        "if os.path.exists(VAE_PATH):\n",
        "    print(f\"‚úÖ VAE found at:\")\n",
        "    print(f\"   {VAE_PATH}\")\n",
        "else:\n",
        "    print(f\"‚ùå VAE not found at:\")\n",
        "    print(f\"   {VAE_PATH}\")\n",
        "    print(f\"   Make sure you uploaded checkpoint-7100 to Google Drive!\")\n",
        "\n",
        "print()\n",
        "for i, path in enumerate(DATASET_PATHS, 1):\n",
        "    if os.path.exists(path):\n",
        "        files = len(os.listdir(path))\n",
        "        print(f\"‚úÖ Dataset {i}: {files} files\")\n",
        "        print(f\"   {path}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Dataset {i} not found\")\n",
        "        print(f\"   {path}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(\"üñ•Ô∏è  GPU Info:\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(\"   ‚úÖ GPU available!\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è  WARNING: No GPU! Runtime > Change runtime type > GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Clone Repository\n",
        "\n",
        "‚ö†Ô∏è **Replace `YOUR_USERNAME`** with your GitHub username first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# üî¥ EDIT THIS LINE - Replace YOUR_USERNAME\n",
        "repo_url = \"https://github.com/YOUR_USERNAME/ai-toolkit-rgba.git\"\n",
        "\n",
        "repo_path = \"/content/ai-toolkit\"\n",
        "\n",
        "if not os.path.exists(repo_path):\n",
        "    print(f\"üì• Cloning {repo_url}...\")\n",
        "    subprocess.run([\"git\", \"clone\", repo_url, repo_path], check=True)\n",
        "    print(\"‚úÖ Clone complete!\")\n",
        "else:\n",
        "    print(\"‚úÖ Already cloned\")\n",
        "\n",
        "os.chdir(repo_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Install Dependencies\n",
        "\n",
        "‚è±Ô∏è This takes ~3-5 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "# Node.js\n",
        "result = subprocess.run([\"node\", \"--version\"], capture_output=True)\n",
        "if result.returncode != 0:\n",
        "    print(\"   Installing Node.js...\")\n",
        "    subprocess.run([\"apt-get\", \"update\", \"-qq\"], capture_output=True)\n",
        "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"-qq\", \"nodejs\", \"npm\"], check=True)\n",
        "print(\"   ‚úÖ Node.js\")\n",
        "\n",
        "# npm packages\n",
        "print(\"   Installing npm packages...\")\n",
        "subprocess.run([\"npm\", \"install\", \"--prefix\", \"ui\"], capture_output=True, check=False)\n",
        "print(\"   ‚úÖ npm\")\n",
        "\n",
        "# localtunnel\n",
        "print(\"   Installing localtunnel...\")\n",
        "subprocess.run([\"npm\", \"install\", \"-g\", \"localtunnel\"], capture_output=True, check=False)\n",
        "print(\"   ‚úÖ localtunnel\")\n",
        "\n",
        "print(\"\\n‚úÖ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Build UI\n",
        "\n",
        "‚è±Ô∏è This takes ~2-3 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"üî® Building Next.js UI...\")\n",
        "result = subprocess.run(\n",
        "    [\"npm\", \"run\", \"build\", \"--prefix\", \"ui\"],\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        "    timeout=300\n",
        ")\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"‚úÖ Build successful!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Build completed with warnings (usually OK)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Start Web UI\n",
        "\n",
        "üöÄ This creates a public URL you can access from anywhere!\n",
        "\n",
        "**Keep this cell running!** The public URL will appear below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "\n",
        "os.chdir(\"/content/ai-toolkit\")\n",
        "UI_PORT = 8675\n",
        "\n",
        "print(\"üöÄ Starting web UI server...\")\n",
        "ui_process = subprocess.Popen(\n",
        "    [\"npm\", \"run\", \"start\", \"--prefix\", \"ui\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "print(\"‚è≥ Waiting 15 seconds for server to start...\")\n",
        "time.sleep(15)\n",
        "\n",
        "print(f\"\\nüåê Creating tunnel on port {UI_PORT}...\\n\")\n",
        "tunnel_process = subprocess.Popen(\n",
        "    [\"lt\", \"--port\", str(UI_PORT), \"--local-host\", \"127.0.0.1\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1\n",
        ")\n",
        "\n",
        "# Read tunnel output\n",
        "url_found = False\n",
        "for line in tunnel_process.stdout:\n",
        "    line = line.strip()\n",
        "    if line:\n",
        "        print(line)\n",
        "    \n",
        "    if \".loca.lt\" in line and not url_found:\n",
        "        url_found = True\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"‚úÖ WEB UI IS LIVE!\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"\\nüîó PUBLIC URL:\\n\\n   {line}\\n\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"\\nüìù What you can do:\")\n",
        "        print(\"   ‚Ä¢ Open the URL in your browser\")\n",
        "        print(\"   ‚Ä¢ Create training jobs (VAE + datasets auto-detected)\")\n",
        "        print(\"   ‚Ä¢ Generate images with LoRA\")\n",
        "        print(\"   ‚Ä¢ Monitor GPU/VRAM\")\n",
        "        print(\"\\n‚è±Ô∏è  Keep this cell running!\")\n",
        "        print(\"   You can open NEW cells to run other commands.\\n\")\n",
        "\n",
        "# Keep alive\n",
        "try:\n",
        "    tunnel_process.wait()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n‚èπÔ∏è  Shutting down...\")\n",
        "    tunnel_process.terminate()\n",
        "    ui_process.terminate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Helper Commands\n",
        "\n",
        "Run these in separate cells while the server is running:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU usage\n",
        "import subprocess\n",
        "result = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True)\n",
        "print(result.stdout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check training outputs\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "output_dir = Path(\"/content/ai-toolkit/output\")\n",
        "if output_dir.exists():\n",
        "    print(\"üìÅ Training outputs:\")\n",
        "    for folder in sorted(output_dir.iterdir()):\n",
        "        if folder.is_dir():\n",
        "            print(f\"\\n   üìÇ {folder.name}\")\n",
        "            samples = list(folder.glob(\"*.png\"))\n",
        "            if samples:\n",
        "                print(f\"      Files: {len(samples)}\")\n",
        "else:\n",
        "    print(\"No outputs yet\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
